// We need N bounces given that we want to support complex light paths
#pragma max_recursion_depth 10

// WARNING: This define must be kept in sync with the c# code
#define MAX_RECURSION_DEPTH 10

// HDRP include
#define SHADER_TARGET 50

#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/ShaderLibrary/ShaderVariables.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Material/Builtin/BuiltinData.hlsl"

// Ray tracing includes
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/Raytracing/Shaders/ShaderVariablesRaytracing.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/Raytracing/Shaders/RaytracingIntersection.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/Raytracing/Shaders/RaytracingSampling.hlsl"

// Path tracing includes
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/PathTracing/Shaders/PathTracingCommon.hlsl"

// Input(s)
float4x4 _PixelCoordToViewDirWS;

// Output(s)
RWTexture2D<float4> _CameraColorTextureRW;
RWTexture2D<float4> _AccumulatedFrameTexture;

void addConvergenceCue(uint2 pixelCoord, uint sampleCount, inout float3 color)
{
	uint width, height;
	_CameraColorTextureRW.GetDimensions(width, height);

	// Change color only in a region corresponding to a progress bar, on the bottom 1% of the screen
	if (pixelCoord.y < 0.01 * height && (float)pixelCoord.x / width <= (float)sampleCount / (_RaytracingNumSamples - 1))
	{
		float lum = luminance(color);

		if (lum > 1.0)
		{
			color /= lum;
			lum = 1.0;
		}

		// Make dark color brighter, and vice versa
		color += lum > 0.5 ? -0.5 * lum : 0.05 + 0.5 * lum;
	}
}

[shader("miss")]
void Miss(inout RayIntersection rayIntersection : SV_RayPayload)
{
	rayIntersection.color = SAMPLE_TEXTURECUBE_ARRAY_LOD(_SkyTexture, s_trilinear_clamp_sampler, rayIntersection.incidentDirection, 0.0f, 0);
}

[shader("raygeneration")]
void RayGen()
{
	uint2 LaunchIndex = DispatchRaysIndex();
    uint2 LaunchDim = DispatchRaysDimensions();

	// Pixel coordinate of the current pixel
    uint2 currentPixelCoord = uint2(LaunchIndex.x, LaunchIndex.y);

    // Get the current sample count
	uint sampleCount = _AccumulatedFrameTexture[currentPixelCoord].w;

	// Grab motion blur information (FIXME: should be replaced by something else notifying of a change in the scene)
    float2 velocity;
    DecodeMotionVector(LOAD_TEXTURE2D_X(_CameraMotionVectorsTexture, currentPixelCoord), velocity);

	// Have we reached max sampling?
    if (sampleCount >= _RaytracingNumSamples && !any(velocity))
    {
     	_CameraColorTextureRW[currentPixelCoord] = float4(_AccumulatedFrameTexture[currentPixelCoord].xyz, 1.0);
     	return;
    }

    // Get the scramblingValue of this pixel
    uint2 scramblingValue = ScramblingValue(currentPixelCoord.x, currentPixelCoord.y);

    // Get jittered pixel coordinates (FIXME: dimensions)
    float3 jitteredPixelCoord = float3(currentPixelCoord, 1.0);
    jitteredPixelCoord.x += GetRaytracingNoiseSample(_RaytracingFrameIndex, 2, scramblingValue.x);
    jitteredPixelCoord.y += GetRaytracingNoiseSample(_RaytracingFrameIndex, 3, scramblingValue.y);

    // Compute the ray direction, from those coordinates
	float3 directionWS = -normalize(mul(jitteredPixelCoord, (float3x3)_PixelCoordToViewDirWS));

	// Create the ray descriptor for this pixel
	RayDesc rayDescriptor;
	rayDescriptor.Origin = _WorldSpaceCameraPos;
	rayDescriptor.Direction = directionWS;
	rayDescriptor.TMin = _RaytracingCameraNearPlane;
	rayDescriptor.TMax = _RaytracingRayMaxLength;

	// Create and init the RayIntersection structure for this
	RayIntersection rayIntersection;
	rayIntersection.color = 1.0;
	rayIntersection.incidentDirection = rayDescriptor.Direction;
	rayIntersection.origin = rayDescriptor.Origin;
	rayIntersection.remainingDepth = min(MAX_RECURSION_DEPTH - 1, _RaytracingMaxRecursion);
	rayIntersection.pixelScrambling = scramblingValue;
	rayIntersection.maxRoughness = 0.0;

	// In order to achieve filtering for the textures, we need to compute the spread angle of the pixel
	rayIntersection.cone.spreadAngle = _RaytracingPixelSpreadAngle;
	rayIntersection.cone.width = 0.0f;
	
	// Evaluate the ray intersection
	TraceRay(_RaytracingAccelerationStructure, RAY_FLAG_CULL_BACK_FACING_TRIANGLES, RAYTRACING_OPAQUE_FLAG | RAYTRACING_TRANSPARENT_FLAG, 0, 1, 0, rayDescriptor, rayIntersection);

	// Apply exposure modifier to our path result
	rayIntersection.color *= GetCurrentExposureMultiplier();

	// FIXME: should be based on another criterion than velocity
	// Accumulate the result
    if (any(velocity))
    {
    	sampleCount = 1; // Reset sample count
    }
    else
    {
    	sampleCount++;
    	rayIntersection.color = (_AccumulatedFrameTexture[currentPixelCoord].xyz * (sampleCount - 1) + rayIntersection.color) / sampleCount;
    }
   	_AccumulatedFrameTexture[currentPixelCoord] = float4(rayIntersection.color, sampleCount);

	// Add a little convergence cue to our result (FIXME: definitely not the right way to do it!!)
	addConvergenceCue(currentPixelCoord, sampleCount, rayIntersection.color);

   	_CameraColorTextureRW[currentPixelCoord] = float4(rayIntersection.color, 1.0);
}

// // Useless at the moment
// [shader("closesthit")]
// void ClosestHit(inout RayIntersection rayIntersection : SV_RayPayload, AttributeData attributeData : SV_IntersectionAttributes)
// {   
// 	rayIntersection.color = float3(1.0, 0.0, 0.5);
// }
